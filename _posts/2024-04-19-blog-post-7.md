---
title: 'Paper Explained 6: Learning Diverse Image Colorization'
layout: single
date: 2024-04-19
permalink: /posts/2024/04/blog-post-7/
tags:
  - Paper explained
published: true
use_math: false
---

**Image Colorization** ğŸ–Œï¸ lÃ  quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n mÃ u cho cÃ¡c áº£nh Ä‘en tráº¯ng, giÃºp tÃ¡i táº¡o láº¡i hÃ¬nh áº£nh thá»±c
táº¿ tá»« dá»¯ liá»‡u Ä‘Æ¡n sáº¯c, mang láº¡i tráº£i nghiá»‡m hÃ¬nh áº£nh phong phÃº vÃ  sá»‘ng Ä‘á»™ng. Vá»›i Ä‘áº§u vÃ o lÃ  má»™t áº£nh
xÃ¡m, biá»ƒu thá»‹ cÆ°á»ng Ä‘á»™ sÃ¡ng cá»§a áº£nh, mÃ´ hÃ¬nh sáº½ há»c cÃ¡ch Æ°á»›c tÃ­nh cÃ¡c kÃªnh mÃ u cá»§a áº£nh, táº¡o ra má»™t
hÃ¬nh áº£nh há»£p lÃ½ vÃ  hÃ i hÃ²a vá» máº·t thá»‹ giÃ¡c. Má»™t trong nhá»¯ng bÃ i mÃ  mÃ¬nh Ä‘Æ°á»£c há»c vá» chá»§ Ä‘á» nÃ y Ä‘Ã³ lÃ  bÃ i "Learning Diverse Image Colorization", má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c á»Ÿ [Ä‘Ã¢y](https://arxiv.org/pdf/1612.01958.pdf). BÃ€I NÃ€Y MÃŒNH THáº¤Y **ADVANCED**.

# 1. Giá»›i thiá»‡u

Task tÃ´ mÃ u áº£nh thoáº¡t qua nghe hÆ¡i nháº£m (mÃ¬nh tháº¥y váº­y ğŸ˜), nhÆ°ng tháº­t ra cÃ³ nhiá»u á»©ng dá»¥ng cho Ä‘á»i sá»‘ng hÃ ng ngÃ y cá»§a chÃºng ta, sÆ¡ sÆ¡ qua thÃ¬ nÃ³ cÃ³ thá»ƒ lÃ m cho nhá»¯ng áº£nh tráº¯ng Ä‘en trong quÃ¡ khá»© cÃ³ mÃ u sáº¯c hÆ¡n, Ä‘á»‘i vá»›i lÄ©nh vá»±c ML&DL thÃ¬ cÅ©ng cÃ³ thá»ƒ coi nhÆ° viá»‡c tÃ´ mÃ u lÃ  má»™t cÃ¡ch Ä‘á»ƒ chÃºng ta tÄƒng cÆ°á»ng sá»‘ lÆ°á»£ng dá»¯ liá»‡u hiá»‡n cÃ³ (data augmentation) tháº­m chÃ­ á»Ÿ nhá»¯ng lÄ©nh vá»±c nhÆ° y khoa cÅ©ng sá»­ dá»¥ng tá»›i, nhÆ° lÃ  Ä‘á»ƒ tÄƒng cÆ°á»ng cÃ¡i sáº¯c Ä‘á»™, giÃºp cho cÃ¡c bÃ¡c sÄ© nhÃ¬n vÃ o dá»… chuáº©n Ä‘oÃ¡n hÆ¡n, vÃ  nhiá»u nhiá»u cÃ¡i khÃ¡c. ThÃ¬ cá»¥ thá»ƒ hÆ¡n, bÃ i toÃ¡n tÃ´ mÃ u áº£nh mÃ¬nh nháº¯c Ä‘áº¿n trong bÃ i nÃ y lÃ  nhÆ° sau:

![img_color](/assets/img/blog6/img_color.png){: .align-center}

Song, Ä‘Ã¢y váº«n lÃ  má»™t váº¥n Ä‘á» khÃ´ng dá»… Ä‘á»… tiáº¿p cáº­n, bá»Ÿi vÃ¬ cÃ³ ráº¥t nhiá»u cÃ¡ch Ä‘á»ƒ sinh ra nhiá»u mÃ u khÃ¡c nhau tá»« má»™t táº¥m áº£nh tráº¯ng Ä‘en, quan trá»ng á»Ÿ Ä‘Ã¢y lÃ  **mÃ u Ä‘Æ°á»£c tÃ´ cÃ³ nghÄ©a**, vÃ  ngoÃ i ra, theo nhÆ° paper (viáº¿t vÃ o nÄƒm 2017), táº¡i thá»i Ä‘iá»ƒm Ä‘Ã³, cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ´ mÃ u áº£nh cÃ²n chÆ°a Ä‘Æ°á»£c tá»‘t cho láº¯m, bá»Ÿi vÃ¬ táº¡i thá»i Ä‘iá»ƒm Ä‘Ã³, cÃ¡c phÆ°Æ¡ng phÃ¡p cÅ© chá»‰ Ä‘Æ°a ra Ä‘Æ°á»£c gáº§n nhÆ° lÃ  1 káº¿t quáº£ duy nháº¥t (tá»©c lÃ  chá»‰ cÃ³ 1 táº¥m áº£nh mÃ u, nÃ³ khÃ´ng Ä‘a dáº¡ng láº¯m). 

Vá»›i cÃ¡i váº¥n Ä‘á» nhÆ° trÃªn, **goal cá»§a paper nÃ y lÃ  thiáº¿t káº¿ ra má»™t model cÃ³ kháº£ nÄƒng Ä‘a dáº¡ng áº£nh tÃ´ Ä‘Æ°á»£c tÃ´ mÃ u hÆ¡n (nhÆ°ng mÃ u tÃ´ váº«n pháº£i há»£p lÃ½)**

CÃ¡i hÃ¬nh dÆ°á»›i Ä‘Ã¢y mÃ¬nh bÃª tá»« cÃ¡i paper ra, há» lÃ m trÃªn bá»™ dá»¯ liá»‡u LFW ([Labeled Faces in the Wild](https://vis-www.cs.umass.edu/lfw/))

![result-img](/assets/img/blog6/result-paper.png)

VÃ­ dá»¥ nhÆ° máº¥y cÃ¡i hÃ¬nh nÃ y cá»§a ngÆ°á»i ta, nÃ³ Ä‘a dáº¡ng hÆ¡n háº³n nhá»¯ng cÃ¡i model sáºµn cÃ³ thá»i báº¥y giá», vÃ  má»i ngÆ°á»i lÆ°u Ã½ thÃªm lÃ  sáº½ **cÃ³ kháº£ nÄƒng ráº¥t cao nhá»¯ng sample Ä‘Æ°á»£c táº¡o ra khÃ´ng giá»‘ng ground truth**, nhÆ°ng **Ä‘Ã¢y khÃ´ng pháº£i váº¥n Ä‘á»**, mÃ¬nh sáº½ Ä‘á» cáº­p kÄ© hÆ¡n á»Ÿ nhá»¯ng pháº§n sau.

#### References: 
- Labeled Faces in the Wild - https://vis-www.cs.umass.edu/lfw/
- Learning Diverse Image Colorization - https://arxiv.org/pdf/1612.01958.pdf

# 2. Ã tÆ°á»Ÿng 
Nhá»¯ng bÃ i toÃ¡n tÃ´ mÃ u áº£nh cÃ³ Ä‘iá»ƒm chung trong code Ä‘Ã³ chÃ­nh lÃ  chÃºng ta sáº½ cÃ³ má»™t **input lÃ  áº£nh tráº¯ng Ä‘en (grey-level image)** vÃ  **output lÃ  má»™t trÆ°á»ng 2 kÃªnh mÃ u** thÃ´ng qua má»™t hÃ m Ã¡nh xáº¡ nÃ o Ä‘Ã³. NhÆ° Ä‘á» cáº­p á»Ÿ trÃªn thÃ¬ sáº½ **cÃ³ vÃ´ sá»‘ áº£nh mÃ u khÃ¡c nhau cho cÃ¹ng má»™t áº£nh Ä‘en tráº¯ng**. KhÃ¡c nhau á»Ÿ Ä‘Ã¢y cÃ³ chÄƒng lÃ  á»Ÿ cÆ°á»ng Ä‘á»™ cá»§a mÃ u dá»± Ä‘oÃ¡n, vÃ­ dá»¥ nhÆ° má»™t cÃ¡i sáº½ cÃ³ mÃ u trá»i Ä‘áº­m hÆ¡n, cÃ¡i cÃ²n láº¡i cÃ³ áº£nh mÃ u trá»i nháº¡t hÆ¡n, v.v... Nghe thÃ¬ nhÆ° váº­y, nhá»¯ng phÆ°Æ¡ng phÃ¡p deep learning táº¡i thá»i Ä‘iá»ƒm Ä‘Ã³ cÃ³ váº» khÃ´ng Ä‘Æ°á»£c chuá»™ng cho láº¯m, song dÃ¹ sao, objective cá»§a bÃ i nghiÃªn cá»©u nÃ y lÃ  **táº¡o ra nhiá»u hÃ¬nh áº£nh Ä‘a dáº¡ng mÃ u sáº¯c, Ä‘á»“ng thá»i cÃ³ Ã½ nghÄ©a**. 

Váº¥n Ä‘á» náº±m á»Ÿ chá»— **má»™t trÆ°á»ng mÃ u nÃ o Ä‘Ã³ khÃ´ng chá»‰ phá»¥ thuá»™c vÃ o nhá»¯ng giÃ¡ trá»‹ lÃ¢n cáº­n, nÃ³ cÃ²n chá»‹u áº£nh hÆ°á»Ÿng bá»Ÿi cáº¥u trÃºc khÃ´ng gian (long-scale spatial structure)**, Ä‘iá»u nÃ y khiáº¿n cho viá»‡c sampling chá»‰ duy nháº¥t 1 Ä‘iá»ƒm áº£nh sáº½ lÃ m cho khu vá»±c lÃ¢n cáº­n Ä‘iá»ƒm áº£nh Ä‘Ã³ khÃ´ng Ä‘Æ°á»£c Äƒn khá»›p vá»›i nhau, lÃ m cho hÃ¬nh áº£nh khÃ´ng Ä‘Æ°á»£c thá»±c táº¿. Giáº£i phÃ¡p lÃ  **táº¡o ra Ä‘Æ°á»£c nhiá»u mÃ u khÃ¡c nhau nhÆ°ng pháº£i cÃ¢n báº±ng Ä‘Æ°á»£c giá»¯a Æ°á»›c lÆ°á»£ng cá»§a Ä‘iá»ƒm áº£nh Ä‘Ã³ vá»›i cÃ¡i cáº¥u trÃºc khÃ´ng gian áº£nh**. 

## 2.1 Ã tÆ°á»Ÿng mÃ´ hÃ¬nh

Nhá»¯ng cÃ¡i á»Ÿ trÃªn Ä‘á» cáº­p cÃ³ thá»ƒ tÃ¡i hiá»‡n dÆ°á»›i cÃ´ng thá»©c toÃ¡n, mÃ´ hÃ¬nh chÃºng ta mong muá»‘n sáº½ lÃ  má»™t mÃ´ hÃ¬nh xÃ¡c suáº¥t $P(\mathbf{C}|\mathbf{G})$ cho trÆ°á»ng mÃ u $\mathbf{C}$ dá»±a trÃªn áº£nh xÃ¡m Ä‘áº§u vÃ o $\mathbf{G}$ vÃ  sau Ä‘Ã³ Ä‘á»ƒ táº¡o ra, cháº³ng háº¡n N mÃ u khÃ¡c nhau Ä‘i, lÃºc nÃ y chÃºng ta sáº½ thá»±c hiá»‡n láº¥y máº«u cÃ³ tá»« phÃ¢n phá»‘i xÃ¡c suáº¥t vá»«a Ä‘á» cáº­p á»Ÿ trÃªn: 

$$
\begin{equation}
\{\mathbf{C}_k\}_{k=1}^{N} \sim P(\mathbf{C|G})
\end{equation}
$$

NhÆ°ng do nhá»¯ng cÃ¡i áº£nh thÆ°á»ng cÃ³ sá»‘ chiá»u ráº¥t cao, do Ä‘Ã³ phÃ¢n phá»‘i cá»§a cÃ¡c trÆ°á»ng áº£nh trong tá»± nhiÃªn vÃ  nhá»¯ng Ä‘áº·c trÆ°ng cá»§a áº£nh tráº¯ng Ä‘en trong khÃ´ng gian nhiá»u chiá»u bá»‹ phÃ¢n tÃ¡n. 

ÄÃ¢y lÃ  khÃºc cáº§n lÆ°u Ã½, tÆ°á»Ÿng tÆ°á»£ng bÃ¢y giá» báº¡n Ä‘ang cÃ³ 1 chiá»u dá»¯ liá»‡u thÃ´i, nÃ³ Ä‘ang Ä‘Æ°á»£c hiá»ƒn thá»‹ trÃªn má»™t Ä‘Æ°á»ng tháº³ng 1D nÃ o Ä‘Ã³, tá»± nhiÃªn cÃ¡c báº¡n bá» vÃ´ thÃªm 2 chiá»u ná»¯a, lÃºc nÃ y cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u cÃ³ thá»ƒ náº±m phÃ¢n tÃ¡n á»Ÿ kháº¯p má»i nÆ¡i, nhÆ° cÃ¡i hÃ¬nh dÆ°á»›i Ä‘Ã¢y: 

![1D-3D](/assets/img/blog6/1D-3D.png){: .align-center}

HÃ£y tÆ°á»Ÿng tÆ°á»£ng cÃ¡c báº¡n cÃ³ má»™t tÃºi Ä‘áº§y nhá»¯ng Ä‘Ã´i táº¥t mÃ u sáº¯c khÃ¡c nhau, nhÆ°ng cÃ¡c báº¡n khÃ´ng thá»ƒ nhÃ¬n tháº¥y mÃ u sáº¯c, chá»‰ cÃ³ thá»ƒ phÃ¢n biá»‡t sÃ¡ng tá»‘i giá»‘ng nhÆ° áº£nh xÃ¡m. Nhiá»‡m vá»¥ cá»§a cÃ¡c báº¡n lÃ  ghÃ©p tá»«ng Ä‘Ã´i táº¥t (grey image) vá»›i mÃ u sáº¯c ban Ä‘áº§u cá»§a chÃºng (colorization).

- CÃ¡i tÃºi (High-Dimensional Space): Äiá»u nÃ y Ä‘áº¡i diá»‡n cho khÃ´ng gian nhiá»u chiá»u, nÆ¡i má»—i Ä‘Ã´i táº¥t Ä‘Æ°á»£c mÃ´ táº£ báº±ng nhiá»u Ä‘áº·c Ä‘iá»ƒm ngoÃ i Ä‘á»™ tá»‘i (káº¿t cáº¥u, Ä‘á»™ dÃ y, v.v.). Nhá»¯ng Ä‘áº·c Ä‘iá»ƒm nÃ y giÃºp phÃ¢n biá»‡t cÃ¡c Ä‘Ã´i táº¥t, nhÆ°ng chÃºng khÃ´ng cho cÃ¡c báº¡n biáº¿t mÃ u sáº¯c trá»±c tiáº¿p (vÃ¬ chÃºng Ä‘ang náº±m trong tá»‘i, cÃ¡c báº¡n chá»‰ tháº¥y xÃ¡m Ä‘en thÃ´i, cÃ³ khi tháº¥y toÃ n mÃ u Ä‘en)

- ThÃ¡ch thá»©c (Scattered Distribution): Váº¥n Ä‘á» lÃ  cÃ¡c Ä‘Ã´i táº¥t cÃ³ mÃ u sáº¯c khÃ¡c nhau cÃ³ thá»ƒ cÃ³ má»©c Ä‘á»™ tá»‘i tÆ°Æ¡ng tá»±. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c Ä‘Ã´i táº¥t (cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u) Ä‘Æ°á»£c phÃ¢n tÃ¡n kháº¯p tÃºi (khÃ´ng gian nhiá»u chiá»u). VÃ¬ váº­y, chá»‰ báº±ng cÃ¡ch cáº£m nháº­n Ä‘á»™ tá»‘i, cÃ¡c báº¡n khÃ³ cÃ³ thá»ƒ biáº¿t cháº¯c cháº¯n mÃ¬nh Ä‘ang cáº§m Ä‘Ã´i táº¥t mÃ u gÃ¬ (sá»± mÆ¡ há»“).

- Ãnh xáº¡ sang MÃ u sáº¯c (RGB Space): CÃ¡c báº¡n muá»‘n Ã¡nh xáº¡ tá»«ng Ä‘Ã´i táº¥t (thÃ´ng tin vá» má»©c Ä‘á»™ xÃ¡m) sang mÃ u sáº¯c ban Ä‘áº§u cá»§a chÃºng (khÃ´ng gian RGB, thÆ°á»ng lÃ  3 chiá»u cho Ä‘á», xanh lÃ¡ vÃ  xanh dÆ°Æ¡ng). NhÆ°ng sá»± phÃ¢n bá»‘ ráº£i rÃ¡c khiáº¿n viá»‡c Ã¡nh xáº¡ nÃ y trá»Ÿ nÃªn khÃ´ng rÃµ rÃ ng. Má»™t Ä‘Ã´i táº¥t tá»‘i mÃ u cÃ³ thá»ƒ cÃ³ mÃ u Ä‘á», xanh dÆ°Æ¡ng hoáº·c tháº­m chÃ­ lÃ  Ä‘en.

Do Ä‘Ã³ mÃ  ngÆ°á»i ta má»›i muá»‘n giáº£m cÃ¡i sá»‘ chiá»u biá»ƒu diá»…n xuá»‘ng, cá»¥ thá»ƒ hÆ¡n lÃ  há» muá»‘n tÃ¬m nhá»¯ng cÃ¡i Ä‘áº·c trÆ°ng biá»ƒu diá»…n cho cáº£ $C$ vÃ  $G$ Ä‘á»ƒ cÃ³ thá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c mÃ´ hÃ¬nh xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n vÃ  chiáº¿n lÆ°á»£c cá»§a nhÃ³m tÃ¡c giáº£ lÃ  há» sáº½ biá»ƒu diá»…n kÃªnh mÃ u $C$ báº±ng má»™t giÃ¡ trá»‹ $\mathbf{z}$ (má»™t embedding vector trong latent space), biá»ƒu diá»…n nÃ y sáº½ Ä‘Æ°á»£c há»c thÃ´ng qua má»™t máº¡ng VAE. Káº¿ Ä‘áº¿n há» sá»­ dá»¥ng Mixture Density Network (MDN) Ä‘á»ƒ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c má»™t mÃ´ hÃ¬nh Ä‘iá»u kiá»‡n:

$$
\begin{equation}
{P}(\mathbf{z}|\mathbf{G})
\end{equation}
$$
 
Äá»“ng thá»i cÃ¡c biá»ƒu diá»…n Ä‘áº·c trÆ°ng cá»§a áº£nh xÃ¡m $G$ sáº½ Ä‘Æ°á»£c há»c thÃ´ng qua má»™t máº¡ng CNN sao cho nÃ³ láº¥y Ä‘uá»™c thÃ´ng tin biá»ƒu diá»…n cá»§a cÃ¡i áº£nh xÃ¡m Ä‘Ã³ (VGG cÅ©ng Ä‘Æ°á»£c). Cuá»‘i cÃ¹ng, á»Ÿ giai Ä‘oáº¡n inference, há» sáº½ láº¥y N máº«u tá»« phÃ¢n phá»‘i: 

$$
\begin{equation}
\{\mathbf{z}_k\}_{k=1}^{N} \sim P(\mathbf{z|G})
\end{equation}
$$ 

Sau Ä‘Ã³ sá»­ dá»¥ng VAE decoder Ä‘á»ƒ láº¥y Ä‘Æ°á»£c tá»«ng kÃªnh mÃ u $\mathbf{C}_k$ cho tá»«ng Ä‘iá»ƒm $\mathbf{z}_k$. ÄÆ¡n giáº£n váº­y thÃ´i ğŸ¤“

## 2.2 VAE

NhÆ° Ä‘Ã£ Ä‘á» cáº­p á»Ÿ trÃªn, chÃºng ta mong muá»‘n há»c má»™t biá»ƒu diá»…n $\mathbf{z}$ cÃ³ sá»‘ chiá»u tháº¥p hÆ¡n chiá»u biá»ƒu diá»…n cá»§a trÆ°á»ng mÃ u $C$ , trong paper ["Auto-Encoding Variational Bayes"](https://arxiv.org/abs/1312.6114), cÃ¡c tÃ¡c giáº£ cÃ³ Ä‘Æ°a ra giáº£i phÃ¡p lÃ  chÃºng ta sáº½ tá»‘i Ä‘a hÃ m dÆ°á»›i Ä‘Ã¢y theo $\theta$:

$$
\begin{equation}
\mathbb{E}_{z \sim Q}[\log P (\mathbf{C}|\mathbf{z}, \theta)] - \text{KL}[Q(\mathbf{z}|\mathbf{C}, \theta) \Vert P (\mathbf{z})]
\end{equation}
$$

VÃ  Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y, há» cÃ³ Ä‘áº·t ra nhá»¯ng giáº£ Ä‘á»‹nh khÃ¡c nhau cá»§a cÃ¡c phÃ¢n phá»‘i, cá»¥ thá»ƒ hÆ¡n, háº­u nghiá»‡m $P(\mathbf{C}|\mathbf{z},\theta)$ sáº½ cÃ³ phÃ¢n phá»‘i Gaussian, tá»©c lÃ  $N(\mathbf{C}|f(\mathbf{z}, \theta), \sigma^2)$. CÅ©ng nhá» váº­y mÃ  cÃ¡i váº¿ Ä‘áº§u trong phÆ°Æ¡ng trÃ¬nh (4) sáº½ trá»Ÿ thÃ nh má»™t máº¡ng decoder vá»›i hÃ m loss L2 vá»›i cÃ´ng thá»©c:
$$
\begin{equation}
\|\mathbf{C} - f(\mathbf{z}, \theta)\|^2
\end{equation}
$$. 

MÃ¬nh thÃ¬ khÃ´ng rÃ nh vá» toÃ¡n láº¯m, nhÆ°ng theo mÃ¬nh, vá»›i giáº£ Ä‘á»‹nh vá» háº­u nghiá»‡m nhÆ° váº­y, sau khi gáº¯n vÃ o phÆ°Æ¡ng trÃ¬nh sá»‘ (4) thÃ¬ lÃºc nÃ y giÃ¡ trá»‹ tráº£ ra cá»§a váº¿ Ä‘áº§u cá»§a phÆ°Æ¡ng trÃ¬nh Ä‘Ã³ lÃ :
$$
\begin{equation}
\mathbf{C}|f(\mathbf{z},\theta)
\end{equation}
$$

CÃ¡i nÃ y cÅ©ng Ä‘á»“ng thá»i lÃ  1 dáº¡ng káº¿t quáº£ cá»§a decode, nhÆ° váº­y káº¿t há»£p vá»›i $C$ gá»‘c, viá»‡c mÃ¬nh kÃ©o cÃ¡i giÃ¡ trá»‹ loss $L_2$ xuá»‘ng cÅ©ng Ä‘á»“ng thá»i lÃ  viá»‡c mÃ¬nh kiáº¿m má»™t bá»™ $\theta$ Ä‘á»§ tá»‘t Ä‘á»ƒ $C$ Æ°á»›c lÆ°á»£ng cÃ³ giÃ¡ trá»‹ báº±ng hoáº·c gáº§n báº±ng vá»›i $C$. Giá»‘ng há»‡t vá»›i objective cá»§a phÆ°Æ¡ng trÃ¬nh sá»‘ 4, nhÆ° váº­y giáº£ Ä‘á»‹nh tiÃªn nghiá»‡m nhÆ° váº­y lÃ  há»£p lÃ­. 

BÃªn cáº¡nh háº­u nghiá»‡m trÃªn, cÃ¡c tÃ¡c giáº£ cÅ©ng Ä‘áº·t ra má»™t giáº£ Ä‘á»‹nh khÃ¡c cho phÃ¢n phá»‘i cá»§a $P(\mathbf{z})$ lÃ  má»™t phÃ¢n phá»‘i chuáº©n táº¯c, Ä‘iá»u Ä‘Ã³ lÃ m cho váº¿ sau cá»§a phÆ°Æ¡ng trÃ¬nh (4) khi Ã¡p dá»¥ng giáº£ Ä‘á»‹nh má»›i nÃ y sáº½ mang Ã½ nghÄ©a chÃºng ta sáº½ train 1 máº¡ng encoder cÃ³ dáº¡ng nhÆ° dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ nÃ³ kÃ©o phÃ¢n phá»‘i cá»§a $\mathbf{z}$ vá» vá»›i phÃ¢n phá»‘i chuáº©n.

$$
\begin{equation}
 Q(\mathbf{z}|\mathbf{C} ,\theta) 
\end{equation}   
$$

NhÆ° váº­y lÃ  tá»¥i mÃ¬nh Ä‘Ã£ setup xong pháº§n idea cá»§a VAE, má»™t váº¥n Ä‘á» khÃ¡c xuáº¥t hiá»‡n Ä‘Ã³ lÃ  trong mÃ´ hÃ¬nh, chÃºng ta cÃ³ thá»±c hiá»‡n sampling $z$ tá»« phÃ¢n phá»‘i $Q$ Ä‘Æ°á»£c há»c á»Ÿ trÃªn. Váº¥n Ä‘á» á»Ÿ chá»— nÃ y Ä‘Ã³ lÃ  trong quÃ¡ trÃ¬nh train mÃ´ hÃ¬nh, chÃºng ta khÃ´ng cÃ³ thá»±c hiá»‡n backpropagation Ä‘Æ°á»£c, kiá»ƒu khÃ´ng cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ backprop qua má»™t sampling node. Äá»ƒ kháº¯c phá»¥c Ä‘iá»u nÃ y, cÃ¡c tÃ¡c giáº£ cÃ³ Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p Ä‘i kÃ¨m Ä‘Ã³ thá»§ thuáº­t re-parameterization. Má»i ngÆ°á»i cÃ³ thá»ƒ ngÃ³ sÆ¡ qua hÃ¬nh sau:

![reparam_trick](/assets/img/blog6/reparam_trick.png){: .align-center}

NÃ³i ngáº¯n gá»n lÃ  náº¿u chÃºng ta trá»±c tiáº¿p sampling tá»« phÃ¢n phá»‘i chuáº©n Ä‘á»ƒ cho ra vector Ä‘áº¡i diá»‡n $\mathbf{z}$ thÃ¬ lÃºc cáº­p nháº­t trá»ng sá»‘, giÃ¡ trá»‹ Ä‘áº¡o hÃ m sáº½ khÃ´ng cÃ³ Ä‘i qua Ä‘Ã¢y Ä‘Æ°á»£c. Cho nÃªn thay vÃ o Ä‘Ã³, chÃºng ta sáº½ cÃ³ pháº§n giÃ¡ trá»‹ $\mu$ vÃ  pháº§n phÆ°Æ¡ng sai $\sigma^2$ **láº¥y trá»±c tiáº¿p tá»« 2 layer**, pháº§n ngáº«u nhiÃªn thÃ¬ chÃºng ta sáº½ láº¥y cÃ¡i phÆ°Æ¡ng sai Ä‘Ã³ nhÃ¢n vá»›i má»™t $\epsilon$ cÃ³ phÃ¢n phá»‘i chuáº©n táº¯c. CÃ´ng thá»©c cá»§a $\mathbf{z}$ sau khi chÃºng ta re-parameterization lÃºc nÃ y sáº½ lÃ :

$$
\begin{equation}
\mathbf{z} = \mu + \sigma \odot \epsilon
\end{equation}
$$


## 2.3 MDN
CÃ¡c tÃ¡c giáº£ mong muá»‘n há»c Ä‘Æ°á»£c má»™t mÃ´ hÃ¬nh xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n  giá»¯a áº£nh xÃ¡m $\mathbf{G}$ vá»›i embedding vector $\mathbf{z}$. Do Ä‘Ã³ mÃ  há» sáº½ sá»­ dá»¥ng Mixture Density Networks (MDN). Äiá»u nÃ y cho phÃ©p Ã¡nh xáº¡ 1-nhiá»u, Ä‘iá»u nÃ y há»— trá»£ objective cá»§a nhÃ³m tÃ¡c giáº£ khi Ä‘á» xuáº¥t ra paper nÃ y Ä‘Ã³ lÃ  MDN cho phÃ©p tráº£ ra nhiá»u vector vá»›i nhiá»u Ä‘iá»u kiá»‡n khÃ¡c nhau máº·c dÃ¹ Ä‘áº§u vÃ o cÅ©ng cÃ¹ng lÃ  1 input vector Ä‘Ã³, cho phÃ©p sá»± Ä‘a dáº¡ng mÃ  nhÃ³m tÃ¡c giáº£ Ä‘á» cáº­p. 

Cá»¥ thá»ƒ hÆ¡n vá» MDN, Ä‘Ã¢y lÃ  má»™t dáº¡ng NDE (Neural Density Estimator). CÃ¡i NNE nÃ y cho phÃ©p chÃºng ta rÃºt ra Ä‘Æ°á»£c cÃ¡i phÃ¢n phá»‘i dá»±a vÃ o Ä‘áº§u vÃ o, cá»¥ thá»ƒ hÆ¡n thÃ¬ má»i ngÆ°á»i cá»© liÃªn tÆ°á»Ÿng tá»›i bÃ i toÃ¡n supervised learning nhÆ°ng thay vÃ¬ input lÃ  $x$ output lÃ  $y$, lÃºc nÃ y ta sáº½ cÃ³ output lÃ  phÃ¢n phá»‘i cá»§a $y$ theo $x$. CÃ¡i NDE nÃ y theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ nÃ³ lÃ  má»™t paper thuá»™c NIPS (1998). Vá» pháº§n Mixutre Density Network (MDN) thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ tÃ¬m hiá»ƒu á»Ÿ video [nÃ y](https://www.youtube.com/watch?v=9Is3acKEkF8&t=1025s)

Má»™t váº¥n Ä‘á» vá»›i viá»‡c chá»n phÃ¢n phá»‘i cá»§a ouput y theo input x cÃ³ phÃ¢n phá»‘i Gaussian (unimodal) (giáº£ Ä‘á»‹nh nhÆ° váº­y Ä‘á»ƒ máº¥y bÃ i toÃ¡n há»“i quy dá»… giáº£i quyáº¿t hÆ¡n). NhÆ°ng Ä‘á»“ng thá»i giáº£ Ä‘á»‹nh Ä‘Ã³ láº¡i khÃ´ng á»•n (dá»± Ä‘oÃ¡n tá»‡) cho nhá»¯ng *bÃ i toÃ¡n ngÆ°á»£c* (inverse problem) vá»›i multimodal (khÃ¡c unimodal á»Ÿ trÃªn) distribution. Äá»‘i vá»›i nhá»¯ng bÃ i toÃ¡n ngÆ°á»£c, dá»±a vÃ o dá»¯ kiá»‡n Ä‘Æ°á»£c cho, sáº½ cÃ³ kháº£ nÄƒng chÃºng ta cÃ³ ráº¥t nhiá»u káº¿t quáº£ cÃ¹ng tá»“n táº¡i, nÃ³i cÃ¡ch khÃ¡c Ä‘á»‘i vá»›i cÃ¡c bÃ i toÃ¡n nÃ y, chÃºng ta sáº½ khÃ´ng cÃ³ 1 káº¿t quáº£ duy nháº¥t. Do Ä‘Ã³ mÃ  giáº£ Ä‘á»‹nh xÃ¡c suáº¥t <p>$P(\theta | \mathbf{x})$</p>tuÃ¢n theo phÃ¢n phá»‘i dáº¡ng unimodal lÃ  khÃ´ng cÃ²n chÃ­nh xÃ¡c ná»¯a. Do Ä‘Ã³ mÃ  má»™t phÃ¢n phá»‘i Gaussian, dáº¡ng multimodal sáº½ phÃ¹ há»£p cho bÃ i toÃ¡n dáº¡ng nÃ y. 

ChÃ­nh xÃ¡c hÆ¡n, Ä‘á»ƒ cÃ³ thá»ƒ mÃ´ hÃ¬nh Ä‘Æ°á»£c bÃ i toÃ¡n ngÆ°á»£c vá»›i nhiá»u káº¿t quáº£ phÃ¹ há»£p, chÃºng ta sáº½ sá»­ dá»¥ng má»™t mixture model (cá»¥ thá»ƒ hÆ¡n lÃ  Gaussian Mixture Model) cho $P(y|x)$, cá»¥ thá»ƒ hÆ¡n trong bÃ i toÃ¡n tÃ´ mÃ u áº£nh cá»§a chÃºng ta sáº½ lÃ  $P(\mathbf{z}|\mathbf{G})$.

Vá»›i MDN Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh nhÆ° trÃªn, chÃºng ta sáº½ cá»‘ gáº¯ng lÃ m giáº£m giÃ¡ trá»‹ loss báº±ng cÃ¡ch tá»‘i thiá»ƒu conditional negative log likelihood (tá»©c lÃ  tá»‘i thiá»ƒu $-\log P(\mathbf{z}|\mathbf{G})$). LÃºc nÃ y, hÃ m loss cho mÃ´ hÃ¬nh MDN sáº½ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° bÃªn dÆ°á»›i:


## 2.4 Huáº¥n luyá»‡n

ToÃ n bá»™ quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ³m gá»n qua hÃ¬nh dÆ°á»›i Ä‘Ã¢y:

![training-process](/assets/img/blog6/train.png)

# Code

# Káº¿t quáº£

# Tháº£o luáº­n thÃªm


