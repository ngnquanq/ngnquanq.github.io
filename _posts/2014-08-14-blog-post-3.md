---
title: 'Paper Explained 3: Masked Autoencoders Are Scalable Vision Learners'
date: 2024-02-28
permalink: /posts/2024/02/blog-post-3/
tags:
  - Paper explained
  - Deep Learning
published: True

---

"Mask" aka ğŸ‘º lÃ  má»™t kÄ© thuáº­t Ä‘Æ°á»£c Æ°a chuá»™ng trong lÄ©nh vá»±c NLP. NÃ³ hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch che Ä‘i má»™t pháº§n trong dá»¯ liá»‡u, rá»“i Ä‘oÃ¡n cÃ¡i pháº§n bá»‹ che Ä‘Ã³ dá»±a vÃ o nhá»¯ng cÃ¡i khÃ´ng bá»‹ che ğŸ¤¨ğŸ‘Œ. Má»¥c tiÃªu cá»§a nÃ³ Ä‘Æ¡n giáº£n lÃ  Ä‘á»ƒ mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n chung trong dá»¯ liá»‡u, báº¥t ká»ƒ ngá»¯ cáº£nh cá»¥ thá»ƒ. Váº­y cÃ²n Ä‘á»‘i vá»›i dá»¯ liá»‡u ğŸ–¼ï¸ thÃ¬ cÃ¡i nÃ y xÃ i sao, giá» mÃ¬nh tÃ¬m hiá»ƒu trong bÃ i [nÃ y](https://arxiv.org/pdf/2111.06377.pdf) nháº¿ !!! ğŸ’ª.

# Giá»›i thiá»‡u 
NgÃ y nay máº¥y mÃ´ hÃ¬nh Deep Learning Ä‘Ã£ trá»Ÿ nÃªn quÃ¡ lÃ  máº¡nh cÅ©ng nhÆ° lÃ  cÃ¡i kháº£ nÄƒng cá»§a nÃ³ lÃ  ráº¥t lá»›n, káº¿t há»£p vá»›i viá»‡c pháº§n cá»©ng giá» máº¡nh hÆ¡n vÃ  chuyÃªn dá»¥ng hÆ¡n cho cÃ¡c bÃ i toÃ¡n liÃªn quan Ä‘áº¿n AI lÃ m cho viá»‡c con ngÆ°á»i train mÃ´ hÃ¬nh nhÆ° lÃ  diá»u gáº·p giÃ³ ğŸªğŸƒ. 

BÃªn lá» xÃ­u thÃ¬ Ä‘Ã¢y lÃ  dá»± Ä‘oÃ¡n cho thá»‹ trÆ°á»ng pháº§n cá»©ng cho AI tá»« nÄƒm 2022 cho tá»›i nÄƒm 2030.

![hardware](https://www.precedenceresearch.com/insightimg/Artificial-Intelligence-in-Hardware-Market-Size-2021-to-2030.jpg)

ÄÃ³, nÃ³i chung lÃ  ráº¥t khá»§ng. NhÆ°ng mÃ  ae thá»­ nghá»‰, giá» cÃ¡i gÃ¬ cÅ©ng to ra, kiá»ƒu nhÆ° ae Ä‘ang tuá»•i Äƒn tuá»•i lá»›n Ä‘i, kháº©u pháº§n Äƒn cá»§a ae pháº£i nhiá»u hÆ¡n Ä‘Ãºng kh ? ğŸ¤” (rÃµ rÃ ng luÃ´n). ThÃ¬ máº¥y cÃ¡i model nÃ y cÅ©ng v, giá» mÃ´ hÃ¬nh lá»›n hÆ¡n cáº§n nhiá»u data hÆ¡n, kiá»ƒu kiá»ƒu váº­y Ä‘Ã³. TrÆ°á»›c Ä‘Ã³ train 1M áº£nh cÃ²n khÃ³ khÄƒn chá»© giá» ae train cáº£ chá»¥c M áº£nh trong phÃ²ng cÅ©ng daijoubu thoi. NhÆ°ng mÃ  váº¥n Ä‘á» nÃ¨ ae: **ğŸ¥¹ ? ÄÃ o Ä‘Ã¢u ra data giá» nÃ­ ? ğŸ¥¹**

KhÃ³ tráº£ lá»i liá»n Ä‘Ãºng kh ae =)))))))))))). Äá»ƒ cho ae cÃ³ cÃ¡i nhÃ¬n cá»¥ thá»ƒ hÆ¡n vá» cÃ¡i thá»‹ trÆ°á»ng cÅ©ng gá»i lÃ  ğŸ¤‘ğŸ«°ğŸ’µğŸ’¶ğŸ’· thÃ¬ dÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡i hÃ¬nh (nÃ³i chung tá»« nÄƒm 2019 láº­n) dá»± Ä‘oÃ¡n tÄƒng trÆ°á»Ÿng tá»›i 2025.

![labeling_cost](https://assets-global.website-files.com/62cd5ce03261cb3e98188470/62cd5ce03261cb756e1885e6_1*8aZc2rNfDVjvZ2Qe1Af52g.png)

ÄÃ³, nÃ³i chung lÃ  hao tiá»n. NhÆ°ng mÃ  cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ counter khÃ´ng? CÃ¢u tráº£ lá»i lÃ  YES. CÃ¡i sá»± hÃ¡u Äƒn cá»§a cÃ¡c model ngÃ y nay cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i quyáº¿t báº±ng phÆ°Æ¡ng phÃ¡p âœ¨self-supervised learningâœ¨. 

Cá»¥ thá»ƒ hÆ¡n thÃ¬ cÃ³ má»™t cÃ¡i task cá»¥ thá»ƒ trong NLP, Ä‘Ã³ lÃ  Masking Task, thÃ¬ cÃ¡i nÃ y Ä‘Æ¡n giáº£n lÃ  nÃ³ huáº¥n luyá»‡n mÃ´ hÃ¬nh báº±ng cÃ¡ch dá»± Ä‘oÃ¡n cÃ¡c tá»« bá»‹ thiáº¿u trong cÃ¢u ğŸ‘ºğŸ”®. Cá»¥ thá»ƒ hÆ¡n thÃ¬ Ä‘áº§u tiÃªn nÃ³ tiáº¿n hÃ nh che vÃ i tá»« trong cÃ¢u (Ä‘Æ°Æ¡ng nhiÃªn lÃ  Ã­t tá»« thÃ´i nhÃ©, chá»© che nhiá»u quÃ¡ thÃ¬ khÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£cğŸ‘½ğŸ‘Œ) vÃ  sá»­ dá»¥ng cÃ¡c tá»« cÃ²n láº¡i Ä‘á»ƒ Ä‘oÃ¡n ra tá»« Ä‘Ã³. NhÆ° cÃ¡i hÃ¬nh á»Ÿ dÆ°á»›i nÃ y lÃ  má»™t cÃ¡i vÃ­ dá»¥ cá»¥ thá»ƒ:

![MLM](/assets/img/blog3/mlm.png) 

ThÃ¬ cÃ¡i lá»£i Ã­ch cá»§a cÃ¡i viá»‡c nÃ y lÃ  nÃ³ cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c tá»« dá»±a trÃªn ngá»¯ cáº£nh (Ä‘Æ°Æ¡ng nhiÃªn lÃ  khÃ´ng cáº§n label ğŸ¥‚). CÃ¢u há»i lÃ  Ä‘á»‘i vá»›i hÃ¬nh áº£nh, mÃ¬nh lÃ m váº­y Ä‘Æ°á»£c khÃ´ng? NÃ³i luÃ´n lÃ  Ä‘Æ°á»£c nhÃ©! Giá» mÃ¬nh lÃ m cÃ¡i nÃ y nÃ¨ ae, paper gá»‘c má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c á»Ÿ [Ä‘Ã¢y](https://arxiv.org/pdf/2111.06377.pdf) nha! 

Trong cÃ¡i bÃ i nghiÃªn cá»©u nÃ y, cÃ¡c tÃ¡c giáº£ Ä‘áº·t ra cÃ¢u há»i: **Äiá»u gÃ¬ lÃ m cho masked autoencoder khÃ¡c biá»‡t giá»¯a dá»¯ liá»‡u dáº¡ng chá»¯ vÃ  dá»¯ liá»‡u dáº¡ng áº£nh?**. VÃ  há» tráº£ lá»i cÃ¢u há»i nÃ y báº±ng viá»‡c Ä‘áº·t ra 3 váº¥n Ä‘á» chÃ­nh:

- **KhÃ¡c biá»‡t trong cáº¥u trÃºc mÃ´ hÃ¬nhğŸ—ï¸**: ThÃ´ng thÆ°á»ng, khi sá»­ dá»¥ng dá»¯ liá»‡u cho dáº¡ng áº£nh thÃ¬ ngÆ°á»i ta dÃ¹ng máº¥y cáº¥u trÃºc CNN, cÃ²n cho dá»¯ liá»‡u vÄƒn báº£n thÃ¬ ngÆ°á»i ta dÃ¹ng RNN hoáº·c lÃ  Transformer. CÃ¡i váº¥n Ä‘á» máº¥u chá»‘t khiáº¿n cho ae khÃ´ng Ã¡p dá»¥ng cÃ¡i masking thÃ´ng thÆ°á»ng cho máº¥y máº¡ng CNN lÃ  bá»Ÿi vÃ¬ cÃ¡i phÃ©p tÃ­ch cháº­p nÃ³ chá»‰ hoáº¡t Ä‘á»™ng ok vá»›i nhá»¯ng cÃ¡i grid thÃ´ng thÆ°á»ng chá»© nÃ³ khÃ´ng cÃ³ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡i nÃ o bá»‹ mask vÃ  pháº£i deal sao vá»›i cÃ¡i cell bá»‹ mask trong cÃ¡i grid Ä‘Ã³. ae tháº¥y váº¥n Ä‘á» chÆ°a? NhÆ°ng mÃ  thanks to cáº¥u trÃºc Transformer, cá»¥ thá»ƒ lÃ  mÃ´ hÃ¬nh ViT, mÃ  cÃ¡i nÃ y khÃ´ng cÃ²n lÃ  chÆ°á»›ng ngáº¡i ná»¯a. NÃªn táº¡m thá»i má»™t váº¥n Ä‘á» Ä‘Æ°á»£c giáº£i quyáº¿t.

- **KhÃ¡c biá»‡t trong máº­t Ä‘á»™ thÃ´ng tinğŸ¤¨**: ThÃ¬ cÃ¡i máº­t Ä‘á»™ thÃ´ng tin trong tá»«ng loáº¡i dá»¯ liá»‡u lÃ  khÃ¡c nhau. ae tÆ°á»Ÿng tÆ°á»£ng ngÃ´n ngá»¯ lÃ  do con ngÆ°á»i quy Ä‘á»‹nh, do Ä‘Ã³ trong vÄƒn báº£n, nÃ³ mang tÃ­nh ngá»¯ nghÄ©a cao cÅ©ng nhÆ° máº­t Ä‘á»™ thÃ´ng tin ráº¥t dÃ y Ä‘áº·c, háº§u háº¿t má»i cÃ¢u ae thá»‘t ra Ä‘á»u dÃ­nh dÃ­nh vá»›i nhau, chá»© khÃ´ng pháº£i kiá»ƒu cÃ¢u dÃ i 4 chá»¯ mÃ  4 chá»¯ cháº£ liÃªn quan gÃ¬ nhau =))))))))))) Ä‘á»c nÃ³ cá»© cáº¥n cáº¥n. HÃ¬nh áº£nh thÃ¬ ngÆ°á»£c láº¡i, hÃ¬nh áº£nh tá»“n táº¡i trong tá»± nhiÃªn, con ngÆ°á»i khÃ´ng cÃ³ 'quy ra hÃ¬nh áº£nh' Ä‘Æ°á»£c, ngoÃ i ra hÃ¬nh áº£nh cÃ²n lÃ  loáº¡i dá»¯ liá»‡u cÃ³ tÆ°Æ¡ng quan khÃ´ng gian cao (nÃ y cá»¥m gá»‘c lÃ  heavy spatial redundancy vÃ  Ä‘á» cáº­p Ä‘áº¿n má»‘i liÃªn há»‡ máº­t thiáº¿t giá»¯a cÃ¡c Ä‘iá»ƒm áº£nh trong khÃ´ng gian). Do Ä‘Ã³ mÃ  Ä‘á»‘i vá»›i hÃ¬nh áº£nh, bá»‹ há»¥t má»™t vÃ i chá»— thÃ´i thÃ¬ váº«n dÃ¹ng cÃ¡c dá»¯ liá»‡u lÃ¢n cáº­n Ä‘á»ƒ tÃ¡i cáº¥u trÃºc láº¡i pháº§n bá»‹ khuyáº¿t Ä‘Ã³ chá»‰ cáº§n mÃ´ hÃ¬nh hiá»ƒu Ä‘Æ°á»£c má»™t vÃ i báº£n cháº¥t cÆ¡ báº£n cá»§a hÃ¬nh áº£nh nhÆ° lÃ  Ä‘á»‘i tÆ°á»£ng trong áº£nh, khung cáº£nh trong áº£nh, v.v... MÃ  nhÆ° váº­y thÃ¬ náº¿u nhÆ° chá»‰ che má»™t xÃ­u nhÆ° bÃªn dá»¯ liá»‡u vÄƒn báº£n thÃ´i thÃ¬ dá»… quÃ¡ ğŸ¤¨ğŸ‘ŒğŸ‘. NÃªn nhÃ³m tÃ¡c giáº£ cÃ³ Ä‘á» xuáº¥t mÃ¬nh sáº½ mask pháº§n lá»›n áº£nh, cÃ³ khi mask tá»›i 85% áº£nh luÃ´n, khÃ´ng váº¥n Ä‘á» gÃ¬ cáº¡! ğŸ’¯. CÃ³ 2 má»¥c Ä‘Ã­ch chÃ­nh: **Giáº£m thiá»ƒu dÆ° thá»«a trong tÃ­nh toÃ¡n** (chá»© che xÃ­u thÃ¬ dá»… quÃ¡, tÃ­nh chi ná»¯a, vá»›i cáº£ lÃ m váº­y thÃ¬ pháº£i tÃ­nh toÃ¡n ráº¥t nhiá»u mÃ  hiá»‡u quáº£ mang láº¡i ráº¥t Ã­t) vÃ  **Táº¡o ra má»™t task Ä‘á»§ khÃ³ Ä‘á»ƒ hiá»ƒu nhiá»u hÆ¡n vá» táº¥m áº£nh chá»© khÃ´ng chá»‰ Ä‘Æ¡n giáº£n lÃ  vÃ i báº£n cháº¥t cÆ¡ báº£n cá»§a táº¥m áº£nh** (Ä‘iá»u nÃ y Ã©p cho mÃ´ hÃ¬nh pháº£i há»c nhá»¯ng cÃ¡i khÃ³ hÆ¡n, tá»« Ä‘Ã³ lÃ m tá»‘t hÆ¡n). 

- **Pháº§n decoder**: CÃ³ má»™t sá»± Ä‘á»‘i láº­p trong pháº§n decoder khi dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡i mask cho dá»¯ liá»‡u áº£nh vÃ  dá»¯ liá»‡u vÄƒn báº£n. Hiá»ƒu Ä‘Æ¡n giáº£n thÃ¬ Ä‘á»‘i vá»›i dá»¯ liá»‡u áº£nh, pháº§n nÃ y sáº½ tÃ¡i cáº¥u trÃºc láº¡i á»Ÿ pixel-level, nhÆ° váº­y cÃ³ thá»ƒ tháº¥y ráº±ng cÃ¡c cÃ¡i pixel Ä‘Æ°á»£c tÃ¡i cáº¥u trÃºc nÃ y cÃ³ tÃ­nh ngá»¯ nghÄ©a tháº¥p. Trong khi Ä‘Ã³ Ä‘á»‘i vá»›i dá»¯ liá»‡u vÄƒn báº£n thÃ¬ khÃ¡c, nhÆ° nÃ£y mÃ¬nh nÃ³i lÃ  vÄƒn báº£n lÃ  loáº¡i dá»¯ liá»‡u cÃ³ tÃ­nh ngá»¯ nghÄ©a dÃ y Ä‘áº·c, thÃ¬ cÃ¡i nÃ y tá»« Ä‘Æ°á»£c dá»¯ Ä‘oÃ¡n cÅ©ng pháº£i cÃ³ tÃ­nh ngá»¯ nghÄ©a cao. 

VÃ  tá»« nhá»¯ng nháº­n xÃ©t trÃªn mÃ  nhÃ³m tÃ¡c giáº£ Ä‘Ã£ Ä‘á» xuáº¥t ra mÃ´ hÃ¬nh MAE (Masked AutoEncoder) Ä‘á»ƒ há»c cÃ¡c Ä‘áº·t trÆ°ng cá»§a áº£nh. Vá»›i mÃ´ táº£ ngáº¯n gá»n (chi tiáº¿t vÃ´ sau) vá» mÃ´ hÃ¬nh. MAE sáº½ che máº¥y cÃ¡i patches tá»« cÃ¡i áº£nh Ä‘áº§u vÃ o rá»“i tÃ¡i cáº¥u trÃºc nÃ³ á»Ÿ pixel-level. VÃ  khÃ´ng nhÆ° nhá»¯ng cÃ¡i AE mÃ  ae hay gáº·p, cÃ¡i AE mÃ  tÃ¡c giáº£ giá»›i thiá»‡u lÃ  má»™t cáº¥u trÃºc báº¥t Ä‘á»‘i xá»©ng (báº¥t Ä‘á»‘i xá»©ng trong AE cÃ³ nghÄ©a lÃ  pháº§n encoder vÃ  decoder cÃ³ cÃ¡i kÃ­ch thÆ°á»›c khÃ¡c nhau). Trong khi pháº§n encoder chá»‰ hoáº¡t Ä‘á»™ng Ä‘á»‘i vá»›i nhá»¯ng pháº§n khÃ´ng bá»‹ che thÃ¬ pháº§n decoder hoáº¡t Ä‘á»™ng luÃ´n cáº£ pháº§n bá»‹ che láº«n khÃ´gn bá»‹ che. NÃ³i tÃ³m gá»n thÃ¬ lÃ  nhÆ° váº­y, mÃ¬nh sáº½ giáº£i thÃ­ch cá»¥ thá»ƒ hÆ¡n á»Ÿ pháº§n sau, trÆ°á»›c máº¯t má»i ngÆ°á»i cÃ³ thá»ƒ xem cÃ¡i hÃ¬nh nÃ y Ä‘á»ƒ náº¯m Ä‘Æ°á»£c cÃ¡i mÃ´ hÃ¬nh nÃ y trÃ´ng ra sao: 

![MAE](/assets/img/blog3/MAE.png)

VÃ  khi mÃ¬nh nÃ³i tá»›i viá»‡c tÃ¡i cáº¥u trÃºc láº¡i hÃ¬nh thÃ¬ lÃ  nhÆ° sau:

![Reconstructed](/assets/img/blog3/reconstruct.png)

**REFERENCES**

(1) [https://www.precedenceresearch.com/insightimg/Artificial-Intelligence-in-Hardware-Market-Size-2021-to-2030.jpg](https://www.precedenceresearch.com/insightimg/Artificial-Intelligence-in-Hardware-Market-Size-2021-to-2030.jpg)

(2) [https://www.lightly.ai/post/ai-human-bottleneck](https://www.lightly.ai/post/ai-human-bottleneck)

(3) [https://towardsdatascience.com/understanding-masked-language-models-mlm-and-causal-language-models-clm-in-nlp-194c15f56a5]([https://towardsdatascience.com/understanding-masked-language-models-mlm-and-causal-language-models-clm-in-nlp-194c15f56a5])

(4) [https://arxiv.org/pdf/2111.06377](https://arxiv.org/pdf/2111.06377)

# CÃ¡c khÃ¡i niá»‡m liÃªn quan

## Masked Language Modeling

# Tá»•ng quan mÃ´ hÃ¬nh

# á»¨ng dá»¥ng mÃ´ hÃ¬nh

# Tháº£o luáº­n thÃªm vÃ  nháº­n xÃ©t