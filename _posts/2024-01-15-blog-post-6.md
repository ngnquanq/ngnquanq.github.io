---
title: 'Paper Explained 4: Generative Adversarial Nets'
date: 2024-03-30
permalink: /posts/2024/03/blog-post-4/
tags:
  - Paper explained
  - Deep Learning
published: True
---

GAN là một trong những framework mới và thật sự đột phá trong việc ước lượng một mô hình tạo sinh thông qua quá trình đối ngẫu. Với ý kiến cá nhân của mình thì đây là paper hay và khá phức tạp, với mình thì paper này là mô hình generative đầu tiên mà mình làm và thấy nó cũng ra gì 🤓🫰. So... Let's dive in! Mọi người có thể tìm được paper gốc tại [đây](https://arxiv.org/pdf/1406.2661.pdf)

# Giới thiệu 

Paper này nếu như mọi người lục lại trên arxiv thì có thể thấy nó được ra vào tháng 7 năm 2014. Theo như nhận định của các tác giả vào năm đó thì có thể thấy những mô hình deep learning thời đó **cực thịnh là những mô hình discriminative** (nôm na là mô hình phân loại) - là kiểu mấy cái mô hình, hiểu đơn giản là hàm ánh xạ từ một input có số chiều lớn sang một ouput có số chiều nhỏ hơn và thường phục vụ cho bài toán phân loại, ví dụ như phân loại chữ số viết tay v.v... 

Và cũng thời đó, các mô hình generative (tạo sinh) thì lại có vẻ ít sôi nổi hơn (nhưng giờ thì sôi nổi rồi - 2024). Và cũng lúc này, các tác giả của paper này đã **propose một framework mới**, một framework hoạt động dựa trên quá trình đối ngẫu (adversarial process - mình sẽ giải thích ở phía dưới). 

**Main Idea**: Chúng ta sẽ huấn luyện đồng thời 2 mô hình, một mô hình tạo sinh $G$ và một mô hình phân loại $D$. 2 mô hình này có vai trò khác nhau. Đối với mô hình $G$, mô hình này sẽ cố gắng **ước lượng phân phối của dữ liệu**. Trong khi đó đối với mô hình $D$, nó sẽ **phân loại xem một sample nào đó là đến từ $G$ hay đến từ bộ dữ liệu gốc**. Mong muốn của mô hình $G$ đó là cực đại khả năng mô hình $D$ đưa ra một kết luận sai (dân dã hơn là $G$ phải giỏi tới mức mà $D$ không phát hiện được sample đi ra từ $G$ là giả hay thật). Còn $D$ lúc chúng ta huấn luyện thì đương nhiên lúc nào chúng ta cũng muốn $D$ phân biệt được rồi (dân dã hơn là $D$ cũng phải đủ trình để lúc nào cũng check var được thằng e $G$). Do đó có thể thấy framework này là thuộc dạng minimax two-player game. 

Như vậy, thứ mà chúng ta mong muốn trong quá trình train (theo lý thuyết) là như sau: $G$ có thể ước lượng được phân phối của bộ dữ liệu (ước lượng chính xác) và output của $D$ luôn là $0.5$. 

# Ý tưởng chính

Hồi này ở đoạn trên mình đã có đề cập về cái main idea của cái framework này, bây giờ mình sẽ nói cụ thể hơn (với ví dụ 👽).

Giả sử đang có 2 phe, một phe làm tiền giả (Generator 💵) và một phe làm cảnh sát (Police 👮). Phe làm tiền giả đang cố gắng **làm tiền giả để qua mặt cảnh sát** và lưu thông lượng tiền giả đó ngoài thị trường, còn phe cảnh sát thì lại không muốn lượng tiền giả đó lưu thông ngoài thị trường nên mới lập **một team để phát hiện tiền giả**. Tới đây là mọi người đã thấy có sự đối nghịch với nhau rồi, chữ `Adversarial` cũng từ đây mà ra. 

Giờ ví dụ cuộc đụng độ này là dài vô hạn (tức là nếu không có gì tác động thì 2 bên vẫn đơm nhau). Thì ở thời điểm xuất phát ($t=0$), bên làm tiền giả tung ra một lô tiền giả, và các anh cảnh sát phải gom được cái lô đó, nhưng cái vấn đề ở đây là do đây là lần đầu tiên cả 2 làm những việc như vậy cho nên họ chưa giỏi. Như vậy, sau khi cái mấy anh cảnh sát bắt được mấy lô tiền giả, mấy anh làm tiền giả lúc này mới thấy không ổn, nên là họ cập nhật lại trình độ, rồi làm tiền giả tốt hơn. Mấy anh cảnh sát cũng không chịu để yên, lúc này mấy ảnh mới cầm cái đống tiền giả đó để học rồi xác định xem cái nào mới là giả, cái nào mới là thật, từ đó mấy ảnh phát hiện tiền giả tốt hơn. 

Và cứ như vậy, cho tới một thời điểm $t = T$ với T rất lớn nào đó, phe làm tiền giả đã có đủ kỹ năng để làm tiền giả y xì đúc tiền thiệt, còn bên cảnh sát thì đã đạt tới giới hạn rồi, bởi vì nhìn tờ tiền nào cũng giống nhau (bên tiền giả làm tiền giả quá tốt) nên lúc này, kết quả tiền giả và tiền thiệt lúc nào cũng là 50%. 

# Code

Ở đây thì mình sẽ thực hiện trên bộ MNIST (bộ này nhẹ, và có hàm để gọi thẳng luôn). 


# Ưu và nhược điểm của framework
Ưu điểm:
- **Khả năng học không giám sát**: GANs có thể học để tạo ra dữ liệu mà không cần nhãn, điều này mở ra khả năng ứng dụng trong nhiều lĩnh vực mà dữ liệu có nhãn là khan hiếm.
- **Chất lượng cao**: Dữ liệu được tạo ra bởi GANs thường có chất lượng cao và rất giống với dữ liệu thực, đặc biệt là trong lĩnh vực sinh ảnh.
- **Ứng dụng đa dạng**: Từ việc tạo ảnh, video giả mạo đến việc tạo dữ liệu huấn luyện cho các mô hình khác, GANs đã mở ra nhiều hướng ứng dụng mới trong AI.

Nhược điểm:
- **Khó huấn luyện**: Việc cân bằng giữa mô hình sinh và mô hình phân biệt là một thách thức lớn, dễ dẫn đến tình trạng mô hình không hội tụ.
- **Mode collapse**: Đây là hiện tượng mà mô hình sinh chỉ tạo ra một số lượng hạn chế các mẫu, làm giảm đa dạng của dữ liệu được tạo ra.
- **Không có đảm bảo về tính chính xác**: Mặc dù dữ liệu tạo ra có thể trông rất thực, nhưng không có đảm bảo rằng nó tuân theo phân phối dữ liệu thực sự.

# Thảo luận thêm