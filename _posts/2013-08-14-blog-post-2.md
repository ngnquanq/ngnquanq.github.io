---
title: 'Paper Explained 2: Pay Attention to MLPs'
date: 2024-02-02
permalink: /posts/2024/02/blog-post-2/
tags:
  - Paper explained
  - Deep Learning
published: true
---

📣 Attention Attention Attention, attention này attention kia, quá nhiều attention. 😅 Trong bài viết này chúng ta sẽ cùng thảo luận về một cách khác cũng đáng nhận được attention, mặc dù không phải attention. 🤔 Chủ đề hôm này của chúng ta sẽ bàn về MLP (cụ thể hơn thì là một biến thể của mạng MLP truyền thống) nói chung và gMLP nói riêng (Highlight của biến thể này là Spatial Gating Unit - Một đơn vị để kiểm soát thông tin). 🎯 Bài này khá hay, cùng đọc nhế !!! 📚🎉

# Giới thiệu

# Cách mô hình hoạt động

# Ứng dụng

# Phân tích ưu và nhược điểm

# Kết luận

# Thảo luận thêm