---
title: 'Paper Explained 2: Pay Attention to MLPs'
date: 2024-02-02
permalink: /posts/2024/02/blog-post-2/
tags:
  - Paper explained
  - Deep Learning
published: true
---

📣 Attention Attention Attention, attention này attention kia, quá nhiều attention. 😅 Trong bài viết này chúng ta sẽ cùng thảo luận về một cách khác cũng đáng nhận được attention, mặc dù không phải attention. 🤔 Chủ đề hôm này của chúng ta sẽ bàn về MLP (cụ thể hơn thì là một biến thể của mạng MLP truyền thống) nói chung và gMLP nói riêng (Highlight của biến thể này là Spatial Gating Unit - Một đơn vị để kiểm soát thông tin). 🎯 Bài này khá hay, cùng đọc nhế !!! 📚🎉

# Giới thiệu.
**!! NOTICE !!** Chữ kiến trúc với chữ mô hình nó hơi nhạy cảm mọi người, nên trong bài này, mình nói kiến trúc là nói chung, còn mô hình là nói cụ thể, chỉ đích danh mô hình đó luôn. z thui, cheers

Các bạn mà có hay cập nhật các thông tin về mấy cái mô hình ngôn ngữ lớn (LLM) như mấy cái Mistral, LLaMa, v.v... thì chắc các bạn cũng đã biết cái phần cốt lõi của mấy mô hình khủng này là kiến trúc Transformer (mà cụ thể hơn là cơ chế attention của nó). 

Những cái kiến trúc của Transformer bao gồm 2 thành phần chính là đó là một cái **kiến trúc recurrent-free** (do đó mà nó cho phép tính cái representation của các tokens một cách song song) và khối **multi-head self-attention** cho phép đa dạng và tổng hợp thông tin giữa các token với nhau. 

Vậy câu hỏi đặt ra ở đây là: "**Cái khối attention đó có cần thiết không?**". Bởi vì xét theo một mặt nào đó, cơ chế attention có một cái inductive bias đó là **tương tác giữa các token nên được tham số một cách dynamic dựa trên biểu diễn đầu vào**, tức là các cái representation có thể thay đổi dựa trên input của mô hình. Nhưng xét theo mặt khác, dựa vào Universal Approximation Theorem, bất kì cấu trúc MLP nào với cũng có thể **xấp xỉ một hàm nào đó với tham số cố định**. Và từ những suy nghĩ trên, mình có thể chuyển câu hỏi vừa đặt ra sang một câu khác cũng khá tương tự: "**Điều gì đóng góp tới thành công của mô hình hơn? Một cái inductive bias yếu trong cơ chế attention hay khả năng xấp xỉ bất kỳ hàm toán học nào của các mạng Neural?**"

Thì bài nghiên cứu của các tác giả, bên cạnh việc trả lời câu hỏi ở trên, tác giả mới giới thiệu một mô hình mới gọi là gMLP bởi vì nó được tạo ra từ kiến trúc MLP và một đơn vị cổng (gating unit). 

Và spoil trước, nó hiệu quả.

# Inductive bias (Thiên kiến quy nạp)
Để dễ hiểu hơn thì mọi người tưởng tượng: Trước tới giờ mọi người chỉ thấy một đàn thiên nga đang bơi trong một cái hồ gần nhà thôi, và đây là nơi duy nhất trong đời mà mọi người có thể quan sát mấy con thiên nga này. Một đống giả thuyết về mấy con thiên nga này mà các bạn có thể đặt ra như sau: "Thiên nga là loài có màu trắng", "Thiên nga chỉ biết bơi", "Thiên nga không biết bay", "Thiên nga đen không tồn tại",v.v... Nói chung là mọi người có đưa ra giả thuyết nào cũng được, do đó mà có vô số giả thuyết có thể được đưa ra, đúng hay sai là chuyện khác. 

![swan](/assets/img/blog2/whitevsblack.png)

Theo lý thuyết, không gian giả thuyết là vô tận (tức là mọi người nghĩ ra bao nhiêu cái giả thuyết cũng được, không giới hạn, đúng sai bàn sau). Cái inductive bias có thể được hiểu như là các giả thuyết được ưu tiên hơn trong không gian giả thuyết. Lấy ví dụ như mấy bài toán như hồi quy tuyến tính, mọi người đang giả định tồn tại mối quan hệ tuyến tính giữa các điểm dữ liệu, và bằng cái giả định này, mọi người đồng thời giới hạn không gian giả thuyết xuống còn mối quan hệ tuyến tính. 

![inductive_bias](/assets/img/blog2/inductive_bias.png)

Vậy trong khuôn khổ của machine learning thì điều này là sao? Mọi người đang có đa dạng dữ liệu (ảnh, chữ, tín hiệu, v.v...) và vô vàn loại mô hình khác nhau (tích chập, hồi quy, v.v...) và mỗi mô hình khác nhau này đều có một cái inductive bias để nó hoạt động tốt khác nhau. Ví dụ như là các mạng CNN được xây dựng dựa trên giả thuyết các điểm pixel nằm gần nhau thì có liên quan tới nhau và mô hình nên học được cái sự liên quan này. 

Và nhân vật chính của chúng ta là kiến trúc Transformer, mô hình này không có một cái inductive bias mạnh, do đó cho phép mô hình khái quát hóa tốt hơn khi nó được huấn luyện với nhiều dữ liệu hơn. Lí do đơn giản bởi vì **kiến trúc Transformer không đặt ra các giả định về đầu vào của mô hình**, mà nó sẽ học thông qua cơ chế attention để biết các đầu vào khác nhau ở các vị trí khác nhau tương tác như thế nào.

# The Universal Approximation Theorem
Có một bài viết hay nói về chủ đề này mà mọi người có thể theo dõi thêm, mình để link ở [đây](https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126) nha. 

![neural_network](/assets/img/blog2/neuralnetwork.png)

Nói đơn giản thì định lí này cho rằng một số lượng đếm được các neuron trong cái mạng neuron có thể xấp xỉ bất kì hàm liên tục nào với sự chính xác ở một mức độ nào đó (chấp nhận sai số) với một hàm kích hoạt như Sigmoid hay ReLU hay một hàm  nào khác.  

# Cách mô hình hoạt động

Trước khi thảo luận thêm, trong bài báo gốc, người ta có dùng 2 từ mà lần đầu đọc mình cũng chưa hiểu rõ những cái đó là gì, để dễ cắt nghĩa hơn thì ở đây mình giải thích lun:

- spatial: Mọi người cứ hiểu lúc mà nói cái axis = 'spatial', tức là người ta đang đề cập đến không gian dòng trong cái ma trận.

- channel: Thường mọi người nghe cái channel này trong mấy cái dạng bài liên quan đến ảnh là nhiều, trong NLP, mà cụ thể trong bài này, khi nhắc tới axis = 'channel', tức là người ta đang đề cập đến không gian cột trong cái ma trận.

Lấy ví dụ như cái câu của mình đang được biểu diễn dưới dạng một ma trận có 50 dòng và 512 cột đi ha, thì có nghĩa cái axis = 'spatial' sẽ là cái trục liên quan đến không gian dòng, tức là liên quan đến số 50, còn nếu axis = 'channel' sẽ là cái trục liên quan đến không gian cột, tức liên quan đến con số 512, trong trường hợp mình vừa nêu, tức là mình đang có 512 channel.

Dưới đây là cấu trúc mô hình, mình sẽ phân tích cụ thể từng thành phần sau:

![gmlp_scheme](/assets/img/blog2/gmlp.png)

Mô hình gMLP này khá là cụ thể, như hình trên, mọi người có thể thấy rằng mô hình sẽ bao gồm một cái chồng gồm $L$ khối đè lên nhau với kích thước và cấu trúc như nhau. 

Biểu diễn đầu vào (a.k.a input embeddings) sẽ là một ma trận có kích thước  $x \in \mathbb{R}^{n \times d}$ với $n$ là độ dài của câu và $d$ là chiều của vector biểu diễn. 

Sau đó ma trận biểu diễn này sẽ được chuẩn hóa (cách thức chuẩn hóa sẽ là chuẩn hóa theo axis = 'channel'). Chuẩn hóa ở đây sẽ là chuẩn hóa theo layer, nếu ai chưa sử dụng cái này trong pytorch thì nó là `torch.nn.LayerNorm` nha mọi người, về cơ bản thì công tức toán của cái này như sau:

$$
y = \frac{{x - E(x)}}{{\sqrt{{Var(x) + \epsilon}}}} \cdot \gamma + \beta
$$

Trong đó cái mean với cái std thì nó lấy từ D chiều ()

Và kế đến sau đó, ma trận được trả ra từ bước chuẩn hóa sẽ được chiếu qua một không gian khác. Bước chiếu này khá đơn giản thôi mọi người, cứ tưởng tượng nó là một hàm toán như kiểu $f: \mathbb{R}^{150 \times 512} \rightarrow \mathbb{R}^{150 \times 256}$, hiểu như vậy thì nó chính là phép `nn.Linear()` trong pytorch luôn. 

Sau đó ma trận mới này sẽ đi qua một hàm kích hoạt nào đó, có thể là hàm ReLU hay GeLU hay gì gì đấy, như vậy thì ta có thể biểu diễn dưới công thức toán học từ sau bước normalize như sau:

$$
Z = \sigma(XU)
$$

Với X là đầu vào, U là một ma trận cho phép ánh xạ X sang một không gian có số chiều khác, còn $\sigma$ là một hàm kích hoạt phi tuyến nào đó như nãy mình nói.  

# Ứng dụng

# Phân tích ưu và nhược điểm

# Kết luận

# Thảo luận thêm