---
title: 'Fundamental 1: Loss function'
date: 2024-03-29
permalink: /posts/2024/03/blog-post-7/
tags:
  - Fundamental Knowledge
published: true
---
Blog này sẽ giới thiệu về các hàm loss (error function hoặc loss function) được sử dụng trong Machine Learning & Deep Learning. Hàm loss trên đời thì nhiều vô kể, với mình, hàm loss chỉ cần đạt đủ tiêu chí để nó trở thành một hàm loss, thì nó sẽ là một hàm loss. Ok, mời mọi người đọc

# 0. Danh mục:
Trong trường hợp bài viết này trở nên quá dài (và table of content không hoạt động, sr 🥹)

# 1. Giới thiệu
**TLDR**: Hàm loss là một hàm toán học giúp hỗ trợ đo lường hiệu quả hoạt động giữa dự đoán của mô hình và giá trị thực tế (có nhiều thước đo hiệu quả hoạt động khác nhau như là thời gian inference, hoặc là nếu mà xét tới các services thì sẽ là thời gian hồi phục sau sự cố, v.v... Nói chung là tùy vào objective của người thiết kế).

Xét trong lĩnh vực học máy, hàm loss **hoạt động như là một kim chỉ nam** giúp điều hướng quá trình huấn luyện mô hình đạt tới **kết quả tối ưu cho các objective của mô hình** (Objective mình không biết dịch ra tiếng việt là sao, nhưng mà có thể hiểu nó như là mục tiêu mình nhắm tới, lấy ví dụ như mấy bạn muốn sai số dự đoán là nhỏ nhất, lúc này objective của mọi người, cái mục tiêu của mọi người là giá trị mất mát đó trở nên nhỏ nhất, hoặc hiểu theo cách khác là mô hình dự đoán đúng nhất). Và do đó, một hàm loss sẽ mang các tính chất sau: 

1. **Đo lường hiệu quả hoạt động**: Đây là một tiêu chí thấy rõ khi mà chúng ta cân nhắc hiệu quả hoạt động của các mô hình, trong quá trình học tập, chúng ta mong muốn mô hình phải có loss càng nhỏ càng tốt. Nó giống như các bạn đi làm bài kiểm tra á, hầu hết bạn nào cũng muốn mình được điểm cao, đồng nghĩa với việc các bạn làm sai ít đi, mà để các bạn làm sai ít đi, thậm chí không sai càng tốt, thì câu trả lời của các bạn (gọi là prediction) và câu trả lời trên cái đáp án (ground truth hoặc là label) nó phải càng sát càng tốt, nó đúng luôn càng vui. 

2. **Kim chỉ nam**: Lấy tiếp cái ví dụ ở trên, giờ ví dụ các bạn đéo học gì hết á, thì điểm các bạn sao cao được, nên là lúc mà có đáp án, lúc mà đối chiếu câu trả lời của các bạn với đáp án, **các bạn biết mình sai ở đâu, cần sửa ở đâu** thì các bạn sẽ sửa ở đó (quá trình mà các bạn sửa như thế nào thì đó là một câu chuyện khác, chắc là sẽ làm một blog khác). Tương tự cho các bài toán học máy, mô hình sau khi dự đoán sai thì sẽ biết nó sai ở chỗ nào để mà sửa cho kết quả tốt hơn. 

3. **Điều chỉnh hành vi**: Lấy tiếp cái ví dụ ở trên, giờ vô phòng thi, lấy ví dụ thi bằng lái đi ha, nó có mấy câu điểm liệt, mấy bạn lệch pha mấy câu đó là mấy bạn liệt luôn, nên là trong trường hợp của các bạn, **có những lỗi sai nặng nề hơn những lỗi sai khác**, do đó các bạn **phải xử lý để không sai các lỗi chí tử**, tức là lúc này, **objective của các bạn sẽ có sự điều chỉnh, hàm loss của các bạn sẽ giúp điều chỉnh**. 

4. **Cân bằng**: Cân bằng ở đây có nghĩa là **cân bằng giữa *bias* và *variance*, cho phép mô hình tổng quát hơn.** Quay lại cái ví dụ ở trên, một học sinh tốt là một học sinh **không học vẹt** và **không học ngu**. Học vẹt ở đây ví dụ như các bạn gặp rồi các bạn mới làm được, còn các bạn không gặp là các bạn tịt luôn (dù là cùng 1 dạng bài, đổi số thôi). Học ngu ở đây là các bạn chả hiểu gì, vô các bạn chọn toàn C (do các bạn thấy cái này có xác suất đúng cao, chứ các bạn không hiểu sao nó cao vậy), lúc này các bạn cũng cúc. 

Một hàm loss cơ bản theo mình cần đáp ứng 2 tiêu chí đầu, một hàm loss tốt sẽ đáp ứng tốt 4 tiêu chí. 

# 2. Các hàm loss phổ biến
Trong học máy, các hàm loss thường được xắp sếp theo các bài toán mà nó đang giải quyết, do đó mà hầu hết nó rơi vào 2 dạng toán là hồi quy hoặc phân loại (các trường hợp đơn giản). Ở mức cơ bản, các bài toán hồi quy thường cho ra giá trị dự đoán là một số thực, trong khi đó các bài toán phân loại thì cho ra giá trị là các nhãn rời rạc. 

## 2.1 Tiêu chí chọn hàm loss

## 2.2 Các yếu tố ảnh hưởng 

## 2.3 Các hàm loss
## 1. Cross Entropy
